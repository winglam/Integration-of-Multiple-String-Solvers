\section{evaluation}
\newcommand{\totaltests}{640\xspace}
\newcommand{\pickedtests}{131\xspace}
\newcommand{\dprlePtests}{16\xspace}
\newcommand{\hampiPtests}{69\xspace}
\newcommand{\zPtests}{46\xspace}

This section describes the setup we evaluated \imss in and the results of our evaluation procedure. More details about the tests we selected for evaluation and their results are made available on our project website~\cite{imss}.

\label{sec:evaluation}
\subsection{Evaluation Setup}
We evaluated our tool with the constraints derived from the tests of the three solvers.
There are \totaltests tests in total (Figure~\ref{tab:solvers}). Of the \totaltests
tests, we evaluated \pickedtests tests. The \pickedtests tests are composed of
\dprlePtests tests from \dprle, \hampiPtests tests from \hampi, and \zPtests from \zstr.
We evaluated only a subset of tests from \hampi and \zstr because the remaining tests
from these two solvers test the same functionality but with different values.
Since the goal of \imss is to ensure that all functionality that is available
from the three constraint solvers is made available through \imss as well, we
omitted tests that did not test additional functionality than the ones we have
selected.

In selecting tests from \zstr and \hampi,
we use the following approach:
\begin{enumerate}
    \item Go through all the tests and categorize them based on their testing functionality.
    \item Count the number of tests in each category.
    \item Reduce tests:
        \begin{itemize}
            \item If the tests contains a functionality or a combination of functionalities that have not been covered, select those tests for evaluation.
            \item Otherwise, omit them from the list of tests for evaluation.
        \end{itemize}
\end{enumerate}
After we have the set of tests, we manually translate each of the tests to be in the
format supported by \imss and run \imss on each of them to collect the following results.
The machine we used to run \imss has the following specifications: 2.8 GHz Intel Core i7, 4.8GB of RAM, and 4 processors in version 14.04 LTS of Ubuntu Desktop.

\subsection{Results}
The three solvers each have different strengths and weaknesses. In this subsection we compare the three solvers in terms of their running time and expressiveness. When comparing the running time of the solvers we only
evaluated tests that the solver was compatible with (produced either SAT or UNSAT result). The complete list of tests that were evaluated for a particular
solver can be found on our project website~\cite{imss}.

\begin{figure}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \dprle & \hampi & \zstr \\
        \hline
        \multicolumn{3}{|l|}{}  \\
        \multicolumn{3}{|l|}{\textbf{\dprle tests}}  \\
        \hline
        1.00 & 30.52 & 13.03 \\
        \hline
        \multicolumn{3}{|l|}{}  \\
        \multicolumn{3}{|l|}{\textbf{\hampi tests}}  \\
        \hline
        0.04 & 1.00 & 0.40 \\
        \hline
        \multicolumn{3}{|l|}{}  \\
        \multicolumn{3}{|l|}{\textbf{\zstr tests}}  \\
        \hline
        0.31 & 11.91 & 1.00 \\
        \hline
    \end{tabular}
    \caption{
        This table shows the increase or decrease in time for the solvers to solve the
        same constraints.
        The data in each cell is calculated by taking the average time the solver
        represented by the column took to solve the tests over the average time the solver who these tests belong to took.
        A number less than 1 represents the fact that the solver represented by the column was able to solve the tests faster than the solver that these
        tests were created for.
    }
    \label{tab:solvercomparetime}
\end{figure}

\textbf{Running Time}
According to the table in Figure~\ref{tab:solvercomparetime}, \hampi on average takes more
time to solve constraints than \dprle or \zstr. More specifically, \hampi takes
30.52 times longer than \dprle did when solving \dprle's tests and 11.91 times
longer than \zstr did when solving \zstr's tests. Moreover, \hampi took longer than both \zstr and \dprle even when solving its own tests.
One of the main reasons for this is that \hampi is a fixed-size string solver. If a test does not have a constraint on
the solution's length, \hampi needs to try different lengths. And if the constraint is unsatisfiable,
\hampi will end up trying to fix the length from 0 to 100 (the length of 50 is a reasonable upperbound~\cite{hampi2009}, but we use 100 in our implementation).

On the other hand, \dprle was the fastest constraint solver we evaluated.
We hypothesize that this is because \hampi has to try different lengths and
\zstr needs to use Z3 SMT solver's plug-in interface.
Since \zstr needs to convert its input format into the Z3 SMT solver's format, this inevitably adds more time to run \zstr.

\begin{figure}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Constraint solver} & \dprle & \hampi & \zstr \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\dprle tests}}  \\
        \hline
        SAT & 14 & 2 & 2 \\
        UNSAT & 0 & 0 & 0 \\
        Incompatible & 2 & 14 & 14 \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\hampi tests}}  \\
        \hline
        SAT & 3 & 49 & 12 \\
        UNSAT & 0 & 20 & 2 \\
        Incompatible & 66 & 0 & 55 \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\zstr tests}}  \\
        \hline
        SAT & 5 & 3 & 38 \\
        UNSAT & 0 & 1 & 8 \\
        Incompatible & 41 & 42 & 0 \\
        \hline
    \end{tabular}
    \caption{
        For each solver's set of tests, this table shows the number of tests each solver
        is incompatible with and for compatible tests, what the output of those tests
        are.
    }
    \label{tab:solvercompareresults}
\end{figure}

\textbf{Expressiveness}
From the previous section, it is apparent that \dprle is the fastest solver, and \hampi is the slowest solver
in terms of their run time. However, there is a trade-off in their functionalities.
Even though, \hampi is the slowest, it is the only solver from these three solvers that supports
context-free grammar definitions. We can see from the table in Figure~\ref{tab:solvercompareresults} that
\dprle and \zstr cannot solve the majority of \hampi's tests, because they do not support context-free grammars like \hampi does.
\dprle was the fastest solver but can solve the fewest number of tests; only 3 of \hampi's tests and 5 of \zstr's tests. This is because
\dprle only supports regular languages represented in an automata.

If we disregard tests with context-free grammars,
\zstr is the most expressive solver as it can solve the highest number of constraints. Also, \zstr
supports a variety of string functionality that the other two solvers do not, such as replace, substring, and length.

For the \pickedtests tests we evaluated our tool on, using any one or combination of the three solvers we selected to evaluate this set of tests would have resulted
in multiple tests being unsolvable. On the other hand, by combining the
expressiveness of all three solvers, \imss can solve them all (for each test,
at least one solver from the three solvers will output SAT or UNSAT).
