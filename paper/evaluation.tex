\section{evaluation}
\newcommand{\totaltests}{640\xspace}
\newcommand{\pickedtests}{131\xspace}
\newcommand{\dprlePtests}{16\xspace}
\newcommand{\hampiPtests}{69\xspace}
\newcommand{\zPtests}{46\xspace}

This section describes the setup we evaluated \imss in and the results of our evaluation procedure. More details about the tests we selected for evaluation and their results are made available on our project website~\cite{imss}.

\label{sec:evaluation}
\subsection{Evaluation Setup}
We evaluated our tool with the constraints derived from the tests of the three solvers.
There are \totaltests tests in total (Figure~\ref{tab:solvers}). Of the \totaltests
tests, we evaluated \pickedtests tests. The \pickedtests tests are composed of
\dprlePtests tests from \dprle, \hampiPtests tests from \hampi, and \zPtests from \zstr.
We evaluated only a subset of tests from \hampi and \zstr because the remaining tests
from these two solvers test the same functionality but with different values.
Since the goal of \imss is to ensure that all functionality that is available
from the three constraint solvers is made available through \imss as well, we
omitted tests that did not test additional functionality than the ones we have
selected.

In selecting tests from \zstr and \hampi,
we use the following approach:
\begin{enumerate}
    \item Go through all the tests and categorize them based on their testing functionality.
    \item Count the number of tests in each category.
    \item Reduce tests:
        \begin{itemize}
            \item If the tests contains a functionality or a combination of functionalities that have not been covered, select those tests for evaluation.
            \item Otherwise, omit them from the list of tests for evaluation.
        \end{itemize}
\end{enumerate}
After we have the set of tests, we manually translate each of the tests to be in the
format supported by \imss and run \imss on each of them to collect the following results.
The machine we used to run \imss has the following specifications: 2.8 GHz Intel Core i7, 4.8GB of RAM, and 4 processors in version 14.04 LTS of Ubuntu Desktop.

\subsection{Results}
The three solvers have different strengths and weaknesses. One solver may be able to support
some functionalities that others cannot. We can compare the three solvers in the two aspects below:
\begin{figure}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Constraint solver} & \dprle & \hampi & \zstr \\
        \hline
        \dprle & 1.00 & 30.52 & 13.03 \\
        \hampi & 0.04 & 1.00 & 0.40 \\
        \zstr & 0.31 & 11.91 & 1.00 \\
        \hline
    \end{tabular}
    \caption{
        This table shows the increase or decrease in time for the solvers to solve the
        same constraints.
        The data in each cell is calculated by taking the average time the solver
        represented by the row took to solve the tests belonging to the solver represented
        by the column over the average time the solver represented by the column
        took to solve the same tests. A number less than 1 represents a decrease in time.
        \ping{I think you got it switched: it should be columns representing solvers, not
        rows representing solvers}
    }
    \label{tab:solvercomparetime}
\end{figure}
\textbf{Running Time:}
According to the table in Figure~\ref{tab:solvercomparetime}, in most cases, \hampi takes more
time to solve constraints as it takes 30.52 times increasing in solving \dprle's tests and 11.91 times
increasing in solving \zstr. Moreover, both \zstr and \dprle take less time solving \hampi's tests.
One of the main reasons is that \hampi is fixed-size string solver. If we do not have a constraint on
the solution's length, \hampi needs to try different lengths. And if the constraint is unsatisfiable,
\hampi will end up trying to fix the length from 0 to 100 (The length of 50 is a reasonable upperbound~\cite{hampi2009}, but we use 100 in our implementation). We can tell from the table as well that
\zstr takes more time to solve constraints than \dprle, because \dprle takes less time to solve
all the three test sets than \zstr does. One reason is that \zstr uses Z3 SMT solver's plug-in interface.
It needs to convert its input format into the \zstr's format first. This adds up more time to run \zstr.

\begin{figure}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Constraint solver} & \dprle & \hampi & \zstr \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\dprle tests}}  \\
        \hline
        SAT & 14 & 2 & 2 \\
        UNSAT & 0 & 0 & 0 \\
        Incompatible & 2 & 14 & 14 \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\hampi tests}}  \\
        \hline
        SAT & 3 & 49 & 12 \\
        UNSAT & 0 & 20 & 2 \\
        Incompatible & 66 & 0 & 55 \\
        \hline
        \multicolumn{4}{|l|}{}  \\
        \multicolumn{4}{|l|}{\textbf{\zstr tests}}  \\
        \hline
        SAT & 5 & 3 & 38 \\
        UNSAT & 0 & 1 & 8 \\
        Incompatible & 41 & 42 & 0 \\
        \hline
    \end{tabular}
    \caption{
        For each solver's set of tests, this table shows the number of tests each solver
        is incompatible with and for compatible tests, what the output of those tests
        are.
    }
    \label{tab:solvercompareresults}
\end{figure}

\textbf{Expressiveness}
From the previous section, \dprle is the fastest solver, and \hampi is the slowest solver
in the aspect of their running time. However, there is a trade-off in their functionalities.
Even though, \hampi is the slowest, it is the only solver from these three solvers that supports
context-free grammar definitions. We can see from the table in Figure~\ref{tab:solvercompareresults} that
\dprle and \zstr cannot solve many \hampi's tests, because they do not support context-free grammars.
\dprle, the fastest solver, can solve very few tests: 3 \hampi's tests, and 5 \zstr's tests, because
it only supports regular languages represented in automata. Without context-free grammars,
\zstr is the most expressive solver as it can solve the highest number of constraints. Also, \zstr
supports a variety of string functionality that the other two solvers do not, such as replace,
substring, length.

For all the \pickedtests tests we evaluated our tool on, \imss can solve them all (For each test,
at least one solver from the three solvers can solve). So we achieve our goal to implement \imss
that is more expressive than the other three solvers.
